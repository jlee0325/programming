{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f7c24d5d-9973-45a1-83be-8bca8b03e576",
      "metadata": {
        "id": "f7c24d5d-9973-45a1-83be-8bca8b03e576"
      },
      "source": [
        "# Assignment: Programming Review\n",
        "## Do Q1 and one other question."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a3fb7b5-0345-447d-840a-59f667fe9c0c",
      "metadata": {
        "id": "4a3fb7b5-0345-447d-840a-59f667fe9c0c"
      },
      "source": [
        "**Q1.** First, think about your priorities in life. What kind of salary do you want to make after graduation? Do you mind getting more schooling? What kind of work-life balance are you looking for? Where do you want to work, geographically? You don't have to write this down here, just think about it.\n",
        "\n",
        "1. Go to the Occupational Outlook Handbook at [https://www.bls.gov/ooh/](https://www.bls.gov/ooh/). Look up \"Data Scientist.\" Read about the job and start collecting data about it from the job profile (e.g. salary, education required, work setting)\n",
        "2. Find 7-10 other jobs that appeal to you, and collect the same data as you did for Data Scientist. Put it all in a spreadsheet.\n",
        "3. Do any of your findings surprise you?\n",
        "4. Rank the jobs you picked from best to worst, and briefly explain why you did so.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a59aca1c",
      "metadata": {},
      "source": [
        "1. After thinking about my priorities, I want a job that pays well soon after graduation (ideally around the $90k–$100k range to start) and has clear growth potential. No, I do not want more schooling. I also care a lot about work-life balance: I want something that’s sustainable most weeks, not constant burnout. Geographically, I’d prefer the Northeast (NYC/DC/Boston) or a hybrid/remote setup.\n",
        "2. Quant Analyst, Business Analyst, Product Manager, Machine Learning Engineer, Cybersecurity, Actuary, UX Researcher\n",
        "3. After that, I picked a set of other jobs that I could realistically see myself doing and looked at them the same way (pay, education needed, work setting, and lifestyle). The jobs that stood out to me were Data Analyst, Data Engineer, Machine Learning Engineer, Business Analyst, Product Manager, Quant Analyst, Cybersecurity Analyst, UX Researcher, and Actuary. Comparing them helped me realize there are a few different “paths,\" some are more technical/building-focused (like data engineering and ML engineering), some are more business-facing (like business analyst and product manager), and some are more specialized lanes (like quant, cybersecurity).\n",
        "4. A few things actually surprised me. First, Product Manager pay can be really high even though it’s not a coding-heavy role, but the tradeoff seems to be more meetings and more pressure since you’re driving decisions. Second, Quant jobs can pay the most, but the work-life balance seems rough and the environment can be intense. Third, Actuary looks like a very stable career with strong long-term pay, but the exam process is a huge commitment that lasts years, which I’m not sure I want."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e9d65ad-3740-43d3-a944-b3653fbeb80c",
      "metadata": {
        "id": "7e9d65ad-3740-43d3-a944-b3653fbeb80c"
      },
      "source": [
        "Depends on student opinions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cfa75b2-aaef-4368-a043-93437887879c",
      "metadata": {
        "id": "7cfa75b2-aaef-4368-a043-93437887879c"
      },
      "source": [
        "**Q2.** Being able to make basic plots to visualize sets of points is really helpful, particularly with data analysis. The pyplot plots are built up slowly by defining elements of the plot, and then using `plt.show()` to create the final plot. This question gives you some practice doing that **iterative** building process.\n",
        "\n",
        "1. Import the `numpy` module as `np` and the `matplotlib.pyplot` package as `plt`.\n",
        "2. Use `np.linspace` to create a grid of 50 points ranging from 0 to 1.\n",
        "3. Create a numpy array $y$ containing the values for the natural logarithm function using the `np.log(x)` function. Create a numpy array $z$ containing the values for the exponential function using the `np.exp(x)` function.\n",
        "4. Use the `plt.scatter(x,y)` method for the $y$ and $z$ vectors to create two scatter plots of the points you've created.\n",
        "5. Use the `plt.show()` method to create the plot.\n",
        "\n",
        "That plot has some problems.\n",
        "\n",
        "6. Before the `plt.show()` call, add labels to the $x$ and $y$ axes using `plt.xlabel(label)` and `plt.ylabel(label)`. Add a title to the graph using `plt.title(title)`, like \"Natural Log and Exponential Functions\".\n",
        "7. That looks a lot better, but we need a legend. When you screate the scatter plots, add the argument `label='Natural Log'` or `label='Exponential'` to the `.scatter` method call. Before the `plt.show()` call, add a `plt.legend(loc = 'lower right')` method call, which creates a legend in the lower right.\n",
        "\n",
        "Now do it again, with slightly less direction:\n",
        "\n",
        "8. Create a grid of 100 equally spaced points ranging from -6.5 to 6.5.\n",
        "9. Use the sine and cosine functions in Numpy to compute the values of those functions for each point on your grid. (You'll have to find out what those functions are.)\n",
        "10. Plot the values of the two functions for the values on the grid on the same plot.\n",
        "11. The scatter plot looks really noisy. Instead of `plt.scatter(x,y)` to make a scatter plot, use `plt.plot(x,y)` to make a line graph.\n",
        "12. Make the plot again, with labels for the axes, a title, and a legend in the lower left instead of the lower right.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9c05ee86-06dc-4ae9-896d-0cb70c4d6c3d",
      "metadata": {
        "id": "9c05ee86-06dc-4ae9-896d-0cb70c4d6c3d"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab57312f-fd41-4763-b38c-3b7c1b062b1c",
      "metadata": {
        "id": "ab57312f-fd41-4763-b38c-3b7c1b062b1c"
      },
      "source": [
        "**Q3.** This is a basic review of some statistics along with practice writing functions. Like we talked about, Python is a general purpose programming language and ships without basic data handling or statistical packages coded in. The beginning of the code chunk below generates random values for you to test your work on; since the random values are generates as NumPy arrays, you'll need to use the Numpy methods `np.sum(x)` to sum the vector $x$ and `np.sqrt(x)` to take the square roots of the values in $x$, as well as the Python function `len(x)` to get the length of $x$.\n",
        "\n",
        "Try to reuse the functions you've already defined as you work through the following questions, rather than rewriting code you've already written.\n",
        "\n",
        "1. Write a function that computes the **sample average** or **mean** of a vector $x$,\n",
        "$$\n",
        "\\bar{x} = \\dfrac{x_1 + x_2 + ... + x_N}{N} = \\dfrac{\\sum_{i=1}^N x_i}{N}.\n",
        "$$\n",
        "Write a function in the code chunk below to compute this quantity, and then use it to compute the mean of $x$.\n",
        "2. Write a function that computes the **sample standard deviation** of a vector $x$,\n",
        "$$\n",
        "s_x = \\sqrt{\\dfrac{(x_1 - \\bar{x})^2 + ... (x_N - \\bar{x})^2 }{N-1}} = \\sqrt{\\dfrac{ \\sum_{i=1}^N (x_i - \\bar{x})^2 }{N-1}}.\n",
        "$$\n",
        "The intuition of this quantity is that it computes roughly the average distance from each point $x_i$ to the sample mean $\\bar{x}$. If it is small, it means all the points are clustered tightly around the mean, and if it is large, it means the points are typically far away from the average. Write a function in the code chunk below to compute this quantity, and then use it to compute the sample standard deviation of $x$.\n",
        "3. Write a function that calls the previous two to **standardize** the values of the vector as a **$z$-score**:\n",
        "$$\n",
        "z = \\dfrac{x-\\bar{x}}{s}.\n",
        "$$\n",
        "The intuition of this quantity is that it is recentering all the values of $x$ so the average is zero and then scaling them by the standard deviation. If the data are normally distributed and $N$ is large, the $z$ score will approximately follow a standard normal distribution. Write a function in the code chunk below to compute this quantity, and then use it to compute the z-scores for $x$.\n",
        "4. The **sample covariance** of two vectors $x=(x_1,...,x_N)$ and $y=(y_1,...,y_N)$ is defined as\n",
        "$$\n",
        "cov(x,y) = \\dfrac{(x_1 - \\bar{x})(y_1-\\bar{y}) + (x_2 - \\bar{x})(y_2-\\bar{y}) + ... + (x_N - \\bar{x})(y_{N}-\\bar{y})}{N-1}\n",
        "$$\n",
        "$$\n",
        "= \\dfrac{\\sum_{i=1}^N (x_i - \\bar{x})(y_i - \\bar{y})}{N-1}.\n",
        "$$\n",
        "The intuition of this quantity is that it looks at the pairs $(x_i, y_i)$ and compares them to the means $(\\bar{x},\\bar{y})$ to determine whether $x$ and $y$ tend to co-vary in the same direction relative to their means: If the values of $x$ and $y$ are typically both above or below the mean values of $x$ and $y$, then $x$ and $y$ will have a positive covariance, but if $x$ is typically above the mean of $x$ when $y$ is typically below the mean of $y$ or vice versa, then they will have a negative covariance. Write a function in the code chunk below to compute this quantity, and then use it to compute the covariance of the generated $x$ and $y$.\n",
        "6. The **sample correlation coefficient** of two vectors $x$ and $y$ is defined as\n",
        "$$\n",
        "r_{xy} = \\dfrac{cov(x,y)}{s_x s_y}\n",
        "$$\n",
        "Use your functions to create a new function that compute this quantity. The intuition of this quantity is that it is like the covariance, but normalized so that its values like between -1 and 1: perfect negative linear association between the variables at -1, no association at 0, and perfect positive linear association between the variables at 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f42ab788-af0c-47a4-a103-46c9a37bfad3",
      "metadata": {
        "id": "f42ab788-af0c-47a4-a103-46c9a37bfad3"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmath\u001b[39;00m\n\u001b[32m      3\u001b[39m np.random.seed(\u001b[32m100\u001b[39m) \u001b[38;5;66;03m# Set the seed for the random number generator\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import math as math\n",
        "np.random.seed(100) # Set the seed for the random number generator\n",
        "rho, sigma_x, sigma_y = -.4, 3, 2 # Variance-Covariance Parameters\n",
        "vcv = np.array([[sigma_x**2, rho*sigma_x*sigma_y],\n",
        "                [rho*sigma_x*sigma_y,sigma_y**2]]) # VCV Matrix\n",
        "mu = np.array([-1,2]) # Population averages\n",
        "sample = np.random.multivariate_normal(mu,vcv,200) # Multivariate normal draws\n",
        "x = sample[:,0]\n",
        "y = sample[:,1]\n",
        "\n",
        "#############################################################################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5924279e-4b74-4941-9819-f028ce3db974",
      "metadata": {
        "id": "5924279e-4b74-4941-9819-f028ce3db974"
      },
      "source": [
        "**Q4.** Optimization is at the core of data science and statistics: Picking the best fit or estimate according to some desirable criteria (e.g. Maximum Likelihood Estimation). In this question, you're going to write a function that finds the highest possible value for some function, and returns the value of the function and the maximizing value.\n",
        "\n",
        "1. Write a function that creates a grid from some value $a$ to a second value $b$ with $N$ steps, computes the value of a function $f$ on that grid, and then finds the maximizers of the function. Have it return a dictionary with the maximum value and the maximizers themselves.\n",
        "2. Use your function to maximize $f(x) = 100 - 2x^2 + 3x$ for values of $a=-1$, $b=1$, and for values of $N=3$, $N=10$, $N=100$, $N=1000$ and $N=5000$.\n",
        "3. The true maximizer of this function is $.75$ and the true maximum value is $101.125$. Is that what you got in the previous step? Why not? How does the quality of the maximization depend on $N$? How does your computed answer change as $N$ gets larger?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c3b32977-7687-4770-8f12-2ab0593f2258",
      "metadata": {
        "id": "c3b32977-7687-4770-8f12-2ab0593f2258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N=    3 | max_value=101.000000 | maximizers=[1.]\n",
            "N=   10 | max_value=101.123457 | maximizers=[0.77777778]\n",
            "N=  100 | max_value=101.124885 | maximizers=[0.73737374 0.75757576]\n",
            "N= 1000 | max_value=101.125000 | maximizers=[0.72772773 0.72972973 0.73173173 0.73373373 0.73573574 0.73773774\n",
            " 0.73973974 0.74174174 0.74374374 0.74574575 0.74774775 0.74974975\n",
            " 0.75175175 0.75375375 0.75575576 0.75775776 0.75975976 0.76176176\n",
            " 0.76376376 0.76576577 0.76776777 0.76976977 0.77177177]\n",
            "N= 5000 | max_value=101.125000 | maximizers=[0.72754551 0.72794559 0.72834567 0.72874575 0.72914583 0.72954591\n",
            " 0.72994599 0.73034607 0.73074615 0.73114623 0.73154631 0.73194639\n",
            " 0.73234647 0.73274655 0.73314663 0.73354671 0.73394679 0.73434687\n",
            " 0.73474695 0.73514703 0.73554711 0.73594719 0.73634727 0.73674735\n",
            " 0.73714743 0.73754751 0.73794759 0.73834767 0.73874775 0.73914783\n",
            " 0.73954791 0.73994799 0.74034807 0.74074815 0.74114823 0.74154831\n",
            " 0.74194839 0.74234847 0.74274855 0.74314863 0.74354871 0.74394879\n",
            " 0.74434887 0.74474895 0.74514903 0.74554911 0.74594919 0.74634927\n",
            " 0.74674935 0.74714943 0.74754951 0.74794959 0.74834967 0.74874975\n",
            " 0.74914983 0.74954991 0.74994999 0.75035007 0.75075015 0.75115023\n",
            " 0.75155031 0.75195039 0.75235047 0.75275055 0.75315063 0.75355071\n",
            " 0.75395079 0.75435087 0.75475095 0.75515103 0.75555111 0.75595119\n",
            " 0.75635127 0.75675135 0.75715143 0.75755151 0.75795159 0.75835167\n",
            " 0.75875175 0.75915183 0.75955191 0.75995199 0.76035207 0.76075215\n",
            " 0.76115223 0.76155231 0.76195239 0.76235247 0.76275255 0.76315263\n",
            " 0.76355271 0.76395279 0.76435287 0.76475295 0.76515303 0.76555311\n",
            " 0.76595319 0.76635327 0.76675335 0.76715343 0.76755351 0.76795359\n",
            " 0.76835367 0.76875375 0.76915383 0.76955391 0.76995399 0.77035407\n",
            " 0.77075415 0.77115423 0.77155431 0.77195439 0.77235447]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def grid_maximize(f, a, b, N):\n",
        "    x = np.linspace(a, b, N)\n",
        "    fx = f(x)\n",
        "\n",
        "    max_val = np.max(fx)\n",
        "    maximizers = x[np.isclose(fx, max_val)]\n",
        "\n",
        "    return {\"max_value\": float(max_val), \"maximizers\": maximizers}\n",
        "\n",
        "\n",
        "f = lambda x: 100 - 2*x**2 + 3*x\n",
        "\n",
        "for N in [3, 10, 100, 1000, 5000]:\n",
        "    out = grid_maximize(f, a=-1, b=1, N=N)\n",
        "    print(\n",
        "        f\"N={N:5d} | max_value={out['max_value']:.6f} | maximizers={out['maximizers']}\"\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c6e5e34-00c0-4101-a1af-34cf61d69ffc",
      "metadata": {
        "id": "3c6e5e34-00c0-4101-a1af-34cf61d69ffc"
      },
      "source": [
        "3. I didn’t get exactly \\(x = 0.75\\), but I did get \\(101.125\\) because the grid search only checks a finite set of points, and \\(0.75\\) usually isn’t exactly on that grid.  \n",
        "When \\(N\\) is small the grid is coarse, so the best point can be noticeably far from \\(0.75\\) and the maximum value is a bit lower than the true maximum.  \n",
        "As \\(N\\) gets larger, the grid points get closer together, so my maximizing \\(x\\) moves toward \\(0.75\\) and the computed maximum approaches \\(101.125\\).  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.12.1)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
